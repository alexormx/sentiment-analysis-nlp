{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a1d6a1",
   "metadata": {},
   "source": [
    "### ðŸ“˜ 1. Imports y configuraciÃ³n de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05ca2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import mlflow\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea9d37",
   "metadata": {},
   "source": [
    "### ðŸ“˜ 2. Cargar los datos\n",
    "En esta secciÃ³n se cargan y dividen los datos preprocesados del pipeline anterior. Este paso es esencial para separar los conjuntos de entrenamiento y validaciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87ce3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar datos procesados y divididos\n",
    "data = np.load(\"../data/processed_split.npz\")\n",
    "\n",
    "X_train = data[\"X_train\"]\n",
    "X_val   = data[\"X_val\"]\n",
    "y_train = data[\"y_train\"]\n",
    "y_val   = data[\"y_val\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc2468",
   "metadata": {},
   "source": [
    "### ðŸ“˜ 3. Arquitectura del Modelo\n",
    "AquÃ­ se define una arquitectura LSTM bidireccional, que mejora el desempeÃ±o al considerar tanto contexto anterior como posterior en el anÃ¡lisis de sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62953bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "lstm_units = 64\n",
    "batch_size = 32\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad826a4a",
   "metadata": {},
   "source": [
    "### ðŸ§  4. Crear modelo (LSTM)\n",
    "Se usan callbacks para evitar sobreajuste (`EarlyStopping`) y guardar automÃ¡ticamente el mejor modelo basado en la mÃ©trica de validaciÃ³n (`ModelCheckpoint`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "937e0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 200, 64)           1280000   \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirecti  (None, 128)               66048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1346177 (5.14 MB)\n",
      "Trainable params: 1346177 (5.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# EarlyStopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',     \n",
    "    patience=2,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Guardar el mejor modelo durante el entrenamiento\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1,\n",
    "    save_format='tf'  # Guardar en formato TensorFlow\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(input_dim=20000, output_dim=embedding_dim, input_length=X_train.shape[1]),\n",
    "    layers.Bidirectional(layers.LSTM(lstm_units)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475719f1",
   "metadata": {},
   "source": [
    "### ðŸ“Š 5. Entrenamiento + MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1216134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.8783\n",
      "Epoch 1: val_accuracy improved from -inf to 0.90125, saving model to best_model\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 418s 166ms/step - loss: 0.2902 - accuracy: 0.8783 - val_loss: 0.2405 - val_accuracy: 0.9013\n",
      "Epoch 2/20\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9260\n",
      "Epoch 2: val_accuracy improved from 0.90125 to 0.91695, saving model to best_model\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 416s 166ms/step - loss: 0.1939 - accuracy: 0.9260 - val_loss: 0.2188 - val_accuracy: 0.9169\n",
      "Epoch 3/20\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9457\n",
      "Epoch 3: val_accuracy did not improve from 0.91695\n",
      "2500/2500 [==============================] - 400s 160ms/step - loss: 0.1488 - accuracy: 0.9457 - val_loss: 0.2155 - val_accuracy: 0.9127\n",
      "Epoch 4/20\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9577Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.91695\n",
      "2500/2500 [==============================] - 398s 159ms/step - loss: 0.1170 - accuracy: 0.9577 - val_loss: 0.2481 - val_accuracy: 0.9140\n",
      "Epoch 4: early stopping\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.2188 - accuracy: 0.9169\n",
      "625/625 [==============================] - 39s 60ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpntiyx3rp/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpntiyx3rp/model/data/model/assets\n",
      "/home/alexor/ailab/project-2-nlp-sentiment/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 918.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 720ms/step\n"
     ]
    }
   ],
   "source": [
    "# MLflow tracking\n",
    "mlflow.set_experiment(\"IMDb Sentiment DL\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Registrar hiperparÃ¡metros\n",
    "    mlflow.log_param(\"embedding_dim\", embedding_dim)\n",
    "    mlflow.log_param(\"lstm_units\", lstm_units)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        validation_data=(X_val, y_val),\n",
    "                        epochs=epochs, \n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stop, checkpoint]\n",
    "                        )\n",
    "\n",
    "    # Registrar mÃ©tricas\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "\n",
    "    #Registrar epocas real y final (early stop)\n",
    "    final_epoch = len(history.history['loss'])\n",
    "    mlflow.log_param(\"epochs_trained\", final_epoch)\n",
    "\n",
    "          \n",
    "    # Guardar localmente (opcional)\n",
    "    model.save(\"../models/sentiment_model.keras\")\n",
    "\n",
    "    # Inferir la signature\n",
    "    signature = infer_signature(X_val, model.predict(X_val))\n",
    "    input_example = X_val[:1]\n",
    "\n",
    "    # Loguear en MLflow\n",
    "    mlflow.keras.log_model(\n",
    "        model=tf.keras.models.load_model(\"best_model\"),\n",
    "        artifact_path=\"sentiment_model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
