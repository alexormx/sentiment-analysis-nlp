# ğŸ§  Sentiment Analysis NLP â€“ Deep Learning with TensorFlow

Este proyecto forma parte del portafolio final del curso de AiLab y aborda un problema de **clasificaciÃ³n de sentimientos** usando **Deep Learning** aplicado a texto (NLP). El objetivo es **predecir si una reseÃ±a escrita por un usuario es positiva o negativa**, utilizando una arquitectura basada en redes neuronales.

---

## ğŸ“‚ Dataset Utilizado

Usamos el dataset de reseÃ±as de productos de Amazon (`amazon_reviews_us_Electronics`) disponible en AWS Open Datasets. Contiene **millones de reseÃ±as** en texto plano con etiquetas de clasificaciÃ³n binaria (`1 = negativo`, `2 = positivo`).

- ğŸ”¢ **TamaÃ±o original:** ~3.6 millones de lÃ­neas
- âœ… **Muestra utilizada:** 100,000 ejemplos
- ğŸ“ **Formato:** `__label__1` / `__label__2` seguido del texto

**ğŸ“Œ Nota:** Por limitaciones de recursos y tiempos de entrenamiento, decidimos utilizar solo **100,000 ejemplos**, lo cual permite obtener resultados representativos sin comprometer rendimiento.

---

## ğŸ“Š AnÃ¡lisis Exploratorio (EDA)

- DistribuciÃ³n de clases:
  - `1 (negativa)`: ~49%
  - `2 (positiva)`: ~51%
- Se verificÃ³ balance adecuado, no fue necesario aplicar tÃ©cnicas de balanceo.
- Se realizÃ³ limpieza del texto eliminando puntuaciÃ³n, mayÃºsculas, y palabras vacÃ­as (stopwords).
- Se revisÃ³ la longitud de las reseÃ±as para determinar un tamaÃ±o de secuencia apropiado (`maxlen=200`).

---

## âš™ï¸ Preprocesamiento y VectorizaciÃ³n

- Se utilizÃ³ `Tokenizer` de Keras con:
  - `num_words=10000`
  - `oov_token="<OOV>"`
- Los textos fueron transformados a secuencias numÃ©ricas (`texts_to_sequences`)
- Padding aplicado con `pad_sequences` (`maxlen=200`, `padding='post'`)
- Etiquetas fueron transformadas de `[1,2]` a `[0,1]` para uso con `SparseCategoricalCrossentropy`.

---

## ğŸ§ª PrÃ³ximos pasos (en siguientes notebooks)

1. **Entrenamiento y validaciÃ³n**
   - Red neuronal (embedding + LSTM/GRU o dense)
   - MÃ©tricas: `Accuracy`, `F1-Score`
2. **EvaluaciÃ³n y exportaciÃ³n**
   - Resultados en test
   - ExportaciÃ³n del modelo
3. **MLflow Tracking**
   - Registro de experimentos
4. **Servicio Batch Prediction**
   - ConstrucciÃ³n de pipelines tipo â€œPau Labartaâ€

---

## ğŸ“Œ DecisiÃ³n sobre muestra de 100,000 ejemplos

Decidimos limitar el nÃºmero de ejemplos a **100,000** debido a:

- Recursos limitados de memoria y GPU
- Tiempo de entrenamiento razonable para pruebas iniciales
- Resultados estadÃ­sticamente significativos con esta muestra

---

## âœ… Conclusiones del EDA & Preprocesamiento

- El dataset estÃ¡ relativamente balanceado.
- La limpieza de texto mejora la calidad del modelo.
- Un tamaÃ±o de secuencia de 200 es adecuado para cubrir mÃ¡s del 90% de los textos.
- El tokenizer de Keras permite una vectorizaciÃ³n eficiente con OOV handling.

---

## ğŸ“ Estructura del proyecto
```bash
ğŸ“¦ sentiment-analysis-nlp/
â”‚
â”œâ”€â”€ 01_eda_feature_pipeline.ipynb # ExploraciÃ³n y vectorizaciÃ³n del texto
â”œâ”€â”€ data/ # Datos crudos o limpios (ignorados por .gitignore)
â”œâ”€â”€ models/ # Modelos entrenados (pendiente)
â”œâ”€â”€ mlruns/ # Directorio de MLflow (pendiente)
â”œâ”€â”€ README.md # Este archivo
â”œâ”€â”€ requirements.txt # Requisitos del proyecto
â””â”€â”€ .gitignore # Archivos a ignorar por Git
```
---

## ğŸ”§ Requisitos

Crea tu entorno y luego instala con:

```bash
pip install -r requirements.txt
```
## ğŸ§° Dependencias principales

- `pandas`
- `numpy`
- `tensorflow`
- `scikit-learn`
- `matplotlib`
---